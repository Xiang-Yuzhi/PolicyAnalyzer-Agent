import requests
import json
from typing import List, Dict, Optional
import sys
import os

# ç¡®ä¿èƒ½å¯¼å…¥åŒçº§æ¨¡å—
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

try:
    from config import Config
except ImportError:
    sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    from config import Config

class PolicySearcher:
    """
    è´Ÿè´£è”ç½‘æ£€ç´¢ (Stage 1: Recall)
    """
    
    @staticmethod
    def search(query: str, num_results: int = 20, 
               source_preference: str = "all", 
               time_range: Optional[str] = None) -> List[Dict]:
        """
        æ‰§è¡Œæœç´¢ -> æ•°æ®æ¸…æ´— -> è¿”å›å€™é€‰åˆ—è¡¨
        """
        refined_query = query
        
        # å¤„ç†å®˜æ–¹æ¥æºåå¥½
        if source_preference == "gov":
            refined_query += " site:.gov.cn"
        
        # å¤„ç†æ—¶é—´èŒƒå›´
        if time_range:
            refined_query += f" {time_range}"
            
        print(f"ğŸ” [SerpApi] æ­£åœ¨æ£€ç´¢å…³é”®è¯: {refined_query} ...")
        
        url = "https://serpapi.com/search"
        params = {
            "engine": "google",
            "q": refined_query,
            "api_key": Config.SERPER_API_KEY,
            "gl": "cn",
            "hl": "zh-cn",
            "num": 40 if source_preference == "all" else 20 # å¹¿åŸŸæœç´¢å¤šæŠ“ä¸€äº›
        }

        try:
            response = requests.get(url, params=params, timeout=15)
            response.raise_for_status()
            data = response.json()
        except Exception as e:
            print(f"âŒ æœç´¢ API è°ƒç”¨å¤±è´¥: {e}")
            return []

        raw_results = data.get("organic_results", [])
        
        candidates = []
        for item in raw_results:
            source_info = item.get("source", "")
            if not source_info and "displayed_link" in item:
                source_info = item["displayed_link"]

            candidates.append({
                "title": item.get("title", ""),
                "link": item.get("link", ""),
                "snippet": item.get("snippet", ""),
                "date": item.get("date", ""),
                "source": source_info
            })

        print(f"ğŸ“¥ [SerpApi] åŸå§‹æŠ“å–: {len(candidates)} æ¡")
        
        # ç»“æœå»é‡ (åŸºäº URL)
        seen_urls = set()
        unique_candidates = []
        for c in candidates:
            if c['link'] not in seen_urls:
                seen_urls.add(c['link'])
                unique_candidates.append(c)
                
        return unique_candidates