import os
import json
import time
from datetime import datetime
from typing import Dict, Any, List

from langchain_community.document_loaders import WebBaseLoader
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

# å¼•å…¥æ ¸å¿ƒæ¨¡å—
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from config import Config
from .rag_engine import rag_engine

class PolicyAnalyzer:
    """
    æ ¸å¿ƒåˆ†æå¼•æ“ (RAG å¢å¼ºç‰ˆ)ï¼š
    1. æŠ“å– URL å†…å®¹
    2. ä½¿ç”¨ RAG å¼•æ“è¿›è¡Œè¯­ä¹‰åˆ‡ç‰‡ä¸ç´¢å¼•
    3. æ£€ç´¢å…³é”®è¯åŸæ–‡ä¾æ®
    4. è°ƒç”¨ LLM è¿›è¡Œæ·±åº¦æŠ•ç ”åˆ†æ
    5. è¾“å‡ºç»“æ„åŒ– JSON
    """

    def __init__(self):
        self.llm = ChatOpenAI(
            api_key=Config.DASHSCOPE_API_KEY,
            base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
            model=Config.MODEL_NAME,
            temperature=0.3,
            model_kwargs={
                "response_format": {"type": "json_object"}
            }
        )

    def scrape_url(self, url: str) -> str:
        """ç½‘é¡µæŠ“å–"""
        print(f"ğŸ•·ï¸ æ­£åœ¨è¯»å–ç½‘é¡µå†…å®¹: {url} ...")
        try:
            loader = WebBaseLoader(url)
            loader.requests_kwargs = {'verify': False, 'timeout': 15}
            docs = loader.load()
            content = "\n\n".join([d.page_content for d in docs])
            return content[:25000] # æ‰©å¤§æŠ“å–èŒƒå›´ï¼Œäº¤ç»™ RAG å¤„ç†
        except Exception as e:
            print(f"âŒ ç½‘é¡µæŠ“å–å¤±è´¥: {e}")
            return ""

    def analyze(self, policy_data: Dict[str, Any], stage_callback=None) -> Dict[str, Any]:
        """
        æ ¸å¿ƒåˆ†æé€»è¾‘ (æ”¯æŒ RAG å’Œ é˜¶æ®µå›è°ƒ)
        """
        url = policy_data.get('link')
        
        # Step 1: æŠ“å–
        if stage_callback: stage_callback("ğŸ“– æ­£åœ¨é˜…è¯»æ”¿ç­–å…¨æ–‡...", 10)
        raw_text = self.scrape_url(url)
        if not raw_text:
            return {"error": "æ— æ³•è·å–ç½‘é¡µå†…å®¹"}

        # Step 2: RAG ç´¢å¼•
        if stage_callback: stage_callback("ğŸ§  æ­£åœ¨æ„å»ºè¯­ä¹‰ç´¢å¼• (RAG)...", 30)
        vector_store = rag_engine.create_index(raw_text)
        
        # Step 3: åŸæ–‡æ£€ç´¢
        if stage_callback: stage_callback("ğŸ” æ­£åœ¨æ£€ç´¢åŸæ–‡å…³é”®æ¡æ¬¾...", 50)
        search_queries = [
            "æ ¸å¿ƒç›‘ç®¡è¦æ±‚å’Œé™åˆ¶æ¡ä»¶",
            "åˆè§„ä¹‰åŠ¡ä¸æ³•å¾‹è´£ä»»",
            "ç”Ÿæ•ˆæ—¥æœŸä¸è¿‡æ¸¡æœŸå®‰æ’",
            "å¯¹æŒ‡æ•°åŸºé‡‘åŠç®¡ç†äººçš„ç›¸å…³è§„å®š"
        ]
        original_citations = rag_engine.get_context_for_analysis(vector_store, search_queries)

        # Step 4: LLM åˆ†æ
        if stage_callback: stage_callback("ğŸ“Š æ­£åœ¨è°ƒç”¨ Qwen-Max è¿›è¡ŒæŠ•ç ”æ·±åº¦åˆ†æ...", 70)
        
        system_prompt = """ä½ ç°åœ¨æ˜¯ã€æ˜“æ–¹è¾¾åŸºé‡‘(EFund)çš„èµ„æ·±æŒ‡æ•°åŸºé‡‘ç»ç†å’Œé¦–å¸­åˆ†æå¸ˆã€‘ã€‚
ä½ çš„ä»»åŠ¡æ˜¯åŸºäºæä¾›çš„æ”¿ç­–åŸæ–‡å’ŒåŸæ–‡æ‘˜å½•ï¼Œæ’°å†™ä¸€ä»½ä¸“ä¸šçš„æ·±åº¦åˆ†ææŠ¥å‘Šã€‚

ã€åˆ†æè¦æ±‚ã€‘
1. **ä¸“ä¸šæ€§**ï¼šç”¨è¯­å‡ç»ƒã€å‡†ç¡®ï¼Œç¬¦åˆé¦–å¸­åˆ†æå¸ˆæ°´å¹³ã€‚
2. **å¤šç»´åº¦**ï¼šåŒºåˆ†çŸ­æœŸ/é•¿æœŸå½±å“ï¼Œæ¶µç›–ä¸åŒç±»å‹çš„æŒ‡æ•°ã€‚
3. **çœŸå®æ€§**ï¼šå¿…é¡»å¼•ç”¨åŸæ–‡å…³é”®æ¡æ¬¾ï¼Œä¸¥ç¦è™šæ„ã€‚

ã€æŠ¥å‘Šç»“æ„è¦æ±‚ - å¿…é¡»è¾¾æ ‡ 2000 å­—ã€‘
1. æ‘˜è¦ (300å­—)
2. æ”¿ç­–è¦ç‚¹ä¸å˜åŒ– (300å­—)
3. **æ”¿ç­–åŸæ–‡æ‘˜å½• (300å­—)** - è¯·é€‰å‡ºæœ€å…³é”®çš„åŸæ–‡æ¡æ¬¾å¹¶è¿›è¡Œé’ˆå¯¹æ€§è§£è¯»
4. å¯¹æŒ‡æ•°åŠå…¶è¡Œä¸šçš„å½±å“ (400å­—)
5. å¯¹æŒ‡æ•°åŸºé‡‘ç®¡ç†å…¬å¸çš„å»ºè®® (400å­—)
6. å¯¹æ˜“æ–¹è¾¾çš„æˆ˜ç•¥è¡ŒåŠ¨å»ºè®® (300å­—)

ã€è¾“å‡º JSON æ ¼å¼ã€‘
{{
  "selected_policy": {{ "title": "{title}", "issuer": "{source}", "publish_date": "{date}", "url": "{url}" }},
  "chat_bullets": ["å¼•ç”¨åŸæ–‡æ¡æ¬¾çš„æ€»ç»“1", "æ€»ç»“2", "æ€»ç»“3", "æ€»ç»“4", "æ€»ç»“5", "æ€»ç»“6"],
  "docx_content": {{
    "æ‘˜è¦": ["..."],
    "æ”¿ç­–è¦ç‚¹ä¸å˜åŒ–": ["..."],
    "æ”¿ç­–åŸæ–‡æ‘˜å½•": ["åŸæ–‡ç»†èŠ‚1", "åŸæ–‡ç»†èŠ‚2", "..."],
    "å¯¹æŒ‡æ•°åŠå…¶è¡Œä¸šçš„å½±å“": ["..."],
    "å¯¹æŒ‡æ•°åŸºé‡‘ç®¡ç†å…¬å¸çš„å»ºè®®": ["..."],
    "å¯¹æ˜“æ–¹è¾¾çš„æˆ˜ç•¥è¡ŒåŠ¨å»ºè®®": ["..."]
  }},
  "word_count_check": {{ "æ€»è®¡": 2000 }}
}}
"""
        
        user_prompt = """
è¯·åŸºäºä»¥ä¸‹å†…å®¹æ’°å†™ 2000 å­—æŠ¥å‘Šï¼š

ã€å…³é”®åŸæ–‡æ‘˜å½•ã€‘
{citations}

ã€å…¨æ–‡æ˜ç»†ã€‘
{content}
"""

        prompt = ChatPromptTemplate.from_messages([
            ("system", system_prompt),
            ("user", user_prompt)
        ])

        chain = prompt | self.llm | StrOutputParser()
        
        try:
            response_str = chain.invoke({
                "title": policy_data.get('title'),
                "source": policy_data.get('source'),
                "date": policy_data.get('date'),
                "url": url,
                "citations": original_citations,
                "content": raw_text[:12000] # å‘é€éƒ¨åˆ†å…¨æ–‡ä½œä¸ºèƒŒæ™¯
            })
            
            if stage_callback: stage_callback("ğŸ“ æ­£åœ¨æ•´ç†è¾“å‡ºæœ€ç»ˆæŠ¥å‘Š...", 90)
            return json.loads(response_str)
            
        except Exception as e:
            print(f"âŒ LLM åˆ†æå¤±è´¥: {e}")
            return {"error": str(e)}