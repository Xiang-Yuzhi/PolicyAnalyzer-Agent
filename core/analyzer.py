import os
import json
import time
from datetime import datetime
from typing import Dict, Any, List

from langchain_community.document_loaders import WebBaseLoader
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

# å¼•å…¥æ ¸å¿ƒæ¨¡å—
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from config import Config
from .rag_engine import rag_engine

class PolicyAnalyzer:
    """
    æ ¸å¿ƒåˆ†æå¼•æ“ (RAG å¢å¼ºç‰ˆ)ï¼š
    1. æŠ“å– URL å†…å®¹
    2. ä½¿ç”¨ RAG å¼•æ“è¿›è¡Œè¯­ä¹‰åˆ‡ç‰‡ä¸ç´¢å¼•
    3. æ£€ç´¢å…³é”®è¯åŸæ–‡ä¾æ®
    4. è°ƒç”¨ LLM è¿›è¡Œæ·±åº¦æŠ•ç ”åˆ†æ
    5. è¾“å‡ºç»“æ„åŒ– JSON
    """

    def __init__(self):
        self.llm = ChatOpenAI(
            api_key=Config.DASHSCOPE_API_KEY,
            base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
            model=Config.MODEL_NAME,
            temperature=0.3,
            model_kwargs={
                "response_format": {"type": "json_object"}
            }
        )

    def scrape_url(self, url: str) -> str:
        """ç½‘é¡µæŠ“å–"""
        print(f"ğŸ•·ï¸ æ­£åœ¨è¯»å–ç½‘é¡µå†…å®¹: {url} ...")
        try:
            loader = WebBaseLoader(url)
            loader.requests_kwargs = {'verify': False, 'timeout': 15}
            docs = loader.load()
            content = "\n\n".join([d.page_content for d in docs])
            return content[:25000] # æ‰©å¤§æŠ“å–èŒƒå›´ï¼Œäº¤ç»™ RAG å¤„ç†
        except Exception as e:
            print(f"âŒ ç½‘é¡µæŠ“å–å¤±è´¥: {e}")
            return ""

    def analyze(self, policy_data: Dict[str, Any], stage_callback=None) -> Dict[str, Any]:
        """
        æ ¸å¿ƒåˆ†æé€»è¾‘ (æ”¯æŒ RAG å’Œ é˜¶æ®µå›è°ƒ)
        """
        url = policy_data.get('link')
        
        # Step 1: æŠ“å–
        if stage_callback: stage_callback("ğŸ“– æ­£åœ¨é˜…è¯»æ”¿ç­–å…¨æ–‡...", 10)
        raw_text = self.scrape_url(url)
        if not raw_text:
            return {"error": "æ— æ³•è·å–ç½‘é¡µå†…å®¹"}

        # Step 2: RAG ç´¢å¼•
        if stage_callback: stage_callback("ğŸ§  æ­£åœ¨æ„å»ºè¯­ä¹‰ç´¢å¼• (RAG)...", 30)
        vector_store = rag_engine.create_index(raw_text)
        
        # Step 3: åŸæ–‡æ£€ç´¢
        if stage_callback: stage_callback("ğŸ” æ­£åœ¨æ£€ç´¢åŸæ–‡å…³é”®æ¡æ¬¾...", 50)
        search_queries = [
            "æ ¸å¿ƒç›‘ç®¡è¦æ±‚å’Œé™åˆ¶æ¡ä»¶",
            "åˆè§„ä¹‰åŠ¡ä¸æ³•å¾‹è´£ä»»",
            "ç”Ÿæ•ˆæ—¥æœŸä¸è¿‡æ¸¡æœŸå®‰æ’",
            "å¯¹æŒ‡æ•°åŸºé‡‘åŠç®¡ç†äººçš„ç›¸å…³è§„å®š"
        ]
        original_citations = rag_engine.get_context_for_analysis(vector_store, search_queries)

        # Step 4: LLM åˆ†æ
        if stage_callback: stage_callback("ğŸ“Š æ­£åœ¨è°ƒç”¨ Qwen-Max è¿›è¡ŒæŠ•ç ”æ·±åº¦åˆ†æ...", 70)
        
        system_prompt = """ä½ æ˜¯ã€æ˜“æ–¹è¾¾åŸºé‡‘é¦–å¸­æ”¿ç­–åˆ†æå¸ˆã€‘ï¼Œè¯·åŸºäºæ”¿ç­–åŸæ–‡æ’°å†™ä¸“ä¸šæŠ•ç ”æŠ¥å‘Šã€‚

ã€æ ¸å¿ƒè¦æ±‚ã€‘ä¸“ä¸šå‡ç»ƒã€å¼•ç”¨åŸæ–‡ã€åŒºåˆ†çŸ­æœŸ/é•¿æœŸå½±å“

ã€æŠ¥å‘Šç»“æ„ (å…±çº¦1800å­—)ã€‘
1. **æ‘˜è¦** (250å­—): æ”¿ç­–èƒŒæ™¯ã€æ ¸å¿ƒå˜åŒ–ã€ä¸»è¦å½±å“
2. **æ”¿ç­–è¦ç‚¹** (250å­—): ç›‘ç®¡è§„å®šã€åˆè§„è¦æ±‚ã€å…³é”®æ¡æ¬¾
3. **åŸæ–‡æ‘˜å½•** (200å­—): é€‰å–æœ€å…³é”®çš„2-3æ¡åŸæ–‡å¹¶ç®€è¦è§£è¯»
4. **å¸‚åœºå½±å“** (400å­—): çŸ­æœŸå†²å‡»(3-6æœˆ) + é•¿æœŸè¶‹åŠ¿(1-3å¹´)
5. **æ˜“æ–¹è¾¾è¡ŒåŠ¨å»ºè®®** (400å­—): äº§å“ç­–ç•¥ã€ä¸šåŠ¡è°ƒæ•´ã€èµ„æºé…ç½®
6. **é£é™©æç¤º** (100å­—): éœ€å…³æ³¨çš„ä¸ç¡®å®šæ€§

ã€è¾“å‡ºJSONæ ¼å¼ã€‘
{{
  "selected_policy": {{"title": "{title}", "issuer": "{source}", "publish_date": "{date}", "url": "{url}"}},
  "chat_bullets": ["æ ¸å¿ƒè§‚ç‚¹1(å«åŸæ–‡å¼•ç”¨)", "æ ¸å¿ƒè§‚ç‚¹2", "æ ¸å¿ƒè§‚ç‚¹3", "æ ¸å¿ƒè§‚ç‚¹4", "æ ¸å¿ƒè§‚ç‚¹5", "æ ¸å¿ƒè§‚ç‚¹6"],
  "docx_content": {{
    "æ‘˜è¦": ["æ®µè½1", "æ®µè½2"],
    "æ”¿ç­–è¦ç‚¹": ["è¦ç‚¹1", "è¦ç‚¹2", "è¦ç‚¹3"],
    "åŸæ–‡æ‘˜å½•": ["åŸæ–‡1åŠè§£è¯»", "åŸæ–‡2åŠè§£è¯»"],
    "å¸‚åœºå½±å“": ["çŸ­æœŸå½±å“", "é•¿æœŸå½±å“"],
    "æ˜“æ–¹è¾¾è¡ŒåŠ¨å»ºè®®": ["äº§å“ç­–ç•¥", "ä¸šåŠ¡è°ƒæ•´å»ºè®®"],
    "é£é™©æç¤º": ["é£é™©ç‚¹"]
  }}
}}
"""
        
        user_prompt = """è¯·åŸºäºä»¥ä¸‹æ”¿ç­–å†…å®¹æ’°å†™çº¦1800å­—çš„ä¸“ä¸šåˆ†ææŠ¥å‘Šã€‚

ã€RAGæ£€ç´¢åˆ°çš„å…³é”®åŸæ–‡ã€‘(è¯·ä¼˜å…ˆå¼•ç”¨è¿™äº›æ¡æ¬¾)
{citations}

ã€æ”¿ç­–å…¨æ–‡å‚è€ƒã€‘
{content}

âš ï¸ æ³¨æ„äº‹é¡¹ï¼š
- chat_bullets æ¯æ¡éœ€ç®€æ´æœ‰åŠ›ï¼Œçº¦30-50å­—ï¼Œéœ€åŒ…å«åŸæ–‡ä¾æ®
- å¸‚åœºå½±å“éœ€åŒºåˆ†çŸ­æœŸ(3-6æœˆ)å’Œé•¿æœŸ(1-3å¹´)
- æ˜“æ–¹è¾¾å»ºè®®éœ€å…·ä½“å¯æ“ä½œï¼Œæ¶µç›–äº§å“ã€ä¸šåŠ¡ã€èµ„æºä¸‰æ–¹é¢
- ä¸¥æ ¼è¾“å‡ºJSONæ ¼å¼ï¼Œå‹¿æ·»åŠ markdownæ ‡è®°
"""

        prompt = ChatPromptTemplate.from_messages([
            ("system", system_prompt),
            ("user", user_prompt)
        ])

        chain = prompt | self.llm | StrOutputParser()
        
        try:
            response_str = chain.invoke({
                "title": policy_data.get('title'),
                "source": policy_data.get('source'),
                "date": policy_data.get('date'),
                "url": url,
                "citations": original_citations,
                "content": raw_text[:12000] # å‘é€éƒ¨åˆ†å…¨æ–‡ä½œä¸ºèƒŒæ™¯
            })
            
            if stage_callback: stage_callback("ğŸ“ æ­£åœ¨æ•´ç†è¾“å‡ºæœ€ç»ˆæŠ¥å‘Š...", 90)
            return json.loads(response_str)
            
        except Exception as e:
            print(f"âŒ LLM åˆ†æå¤±è´¥: {e}")
            return {"error": str(e)}